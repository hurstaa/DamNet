{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This orders dams from upstream to downstream, assigning ToDam and FromDam fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7318b035",
   "metadata": {},
   "source": [
    "### Remove duplicate dams on the same flowline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ba4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size before duplicates removed:', noduplicates.shape)\n",
    "NID_sort = noduplicates.sort_values('Hydroseq', ascending = True) # Sort by ascending Hydrosequence.\n",
    "\n",
    "# Convert dataframe to dictionaries (struct-like); basically has format column->value.\n",
    "NID_dict = NID_sort.to_dict(orient = 'records')\n",
    "dupl_ordered_dict = NID.to_dict(orient='records')\n",
    "\n",
    "# Initialize empty list to store indices of non-duplicates.\n",
    "dupind = []\n",
    "\n",
    "# Identify unique values and their counts.\n",
    "Hydroseq = [item['Hydroseq'] for item in dupl_ordered_dict]\n",
    "uniquevals,ia = np.unique(Hydroseq, return_inverse = True)\n",
    "\n",
    "# Count the frequency of each index in ia.\n",
    "bincounts = np.bincount(ia)\n",
    "\n",
    "# Zero out singles.\n",
    "singles = uniquevals[bincounts <= 1]\n",
    "singleidx = [i for i, val in enumerate(Hydroseq) if val in singles]\n",
    "for idx in singleidx:\n",
    "    Hydroseq[idx] = 0\n",
    "    \n",
    "# Overwrite repeats.\n",
    "repeats = uniquevals[bincounts > 1]\n",
    "Hydroseq = np.array([np.where(repeats == val)[0][0] + 1 if val in repeats else val for val in Hydroseq])\n",
    "\n",
    "#Set flags at duplicates as 5\n",
    "flags[repeats] = [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_it = 0; # Initialize a counter.\n",
    "\n",
    "# Pull out fields needed to help with decision tree for removing duplicates.\n",
    "YrC = [item['yrc'] for item in dupl_ordered_dict]\n",
    "sites = [item['IsSite'] for item in dupl_ordered_dict]\n",
    "grands = [item['IsGRanD'] for item in dupl_ordered_dict]\n",
    "usbr = [item['IsUSBR'] for item in dupl_ordered_dict]\n",
    "usace = [item['IsUSACE'] for item in dupl_ordered_dict]\n",
    "MaxStor_m3 = [item['MaxStor_m3'] for item in dupl_ordered_dict]\n",
    "DamH_m = [item['DamH_m'] for item in dupl_ordered_dict]\n",
    "ShortID = [item['ShortID'] for item in dupl_ordered_dict]\n",
    "\n",
    "for i in range(len(Hydroseq)):\n",
    "    if Hydroseq[i] == 0: # If it is not a duplicate, keep it.\n",
    "        dupind.append(i)\n",
    "    elif skip_it > 0: # Or if we already dealt with it, update the counter so it gets skipped.\n",
    "        skip_it -= 1\n",
    "        continue\n",
    "    else: # Else the value is a duplicate.\n",
    "        dup = [idx for idx, val in enumerate(Hydroseq) if val == Hydroseq[i]] # Gives all indices of the duplicates.\n",
    "        dup1 = dup[0]\n",
    "        dupskip = dup1 # Keep track of what the first index was because we will change this.\n",
    "        j = len(dup)\n",
    "        jskip = j # Same for the length of the duplicates.\n",
    "\n",
    "        MM = MaxStor_m3[dup1:dup[j-1]+1] # Pull out storage values at the duplicates.\n",
    "        DamH = DamH_m[dup1:dup[j-1]+1] #Pull out dam heights at the duplicates\n",
    "        SID = ShortID[dup1:dup[j-1]+1] #Pull out ShortIDs at the duplicates\n",
    "#         kept_indices = [i for i, x in enumerate(Hydro) if x not in [Hydroseq[i] for i in dupind]] # If a dam is already snapped to that flowline, remove the flowlines from the options to choose from.\n",
    "\n",
    "#         dup_test = dup\n",
    "                \n",
    "#         if len(dup_test) == 0: # All of the flowline options have already been used, in which case just keep them all. Duplicate snaps are removed later.\n",
    "#             dup_test = dup\n",
    "        \n",
    "#         dup = dup_test\n",
    "        \n",
    "        dup1 = dup[0]\n",
    "        j = len(dup)\n",
    "        \n",
    "        NoYr = [index for index, value in enumerate(YrC[dup1:dup[j-1]+1]) if value == 0] #pull out dams that don't have a year completed\n",
    "        Year_Compl = [index for index, value in enumerate(YrC[dup1:dup[j-1]+1]) if value != 0] #pull out dams that do have a completion year\n",
    "        siteloc = [index for index, value in enumerate(sites[dup1:dup[j-1]+1]) if value == 1] #sites\n",
    "        GRanDloc = [index for index, value in enumerate(grands[dup1:dup[j-1]+1]) if value == 1] #GRanD dams\n",
    "        USBRloc = [index for index, value in enumerate(usbr[dup1:dup[j-1]+1]) if value == 1] #USBR dams\n",
    "        USACEloc = [index for index, value in enumerate(usace[dup1:dup[j-1]+1]) if value == 1] #USACE dams\n",
    "        \n",
    "        if len(siteloc) > 0: # If any of the dams are sites, choose that.\n",
    "            dupind.append(dup[siteloc])\n",
    "            continue #may not need these continues?\n",
    "        elif len(GRanDloc) > 0: # If GRanD\n",
    "            dup = dup[GRanDloc]\n",
    "            \n",
    "            if len(dup) > 1: #if for some reason multiple GRanD snapped to same flowline, keep both and print a warning\n",
    "                dupind.append(dup)\n",
    "                print('Error: Two GRanD dams snapped to the same flowline!')\n",
    "            else:\n",
    "                dupind.append(dup)\n",
    "            continue\n",
    "        elif len(USBRloc) > 0: #if usbr\n",
    "            dupind.append(dup[USBRloc])\n",
    "            continue\n",
    "        elif len(USACEloc) > 0: #if usace\n",
    "            dupin.append(dup[USACEloc])\n",
    "            continue\n",
    "        elif len(YearCompl) > 0: #if any of the dams have a completion year\n",
    "            if len(YearCompl)<len(dup): #if all of the dams don't have a completion year, get rid of the ones that don't\n",
    "                dup = np.delete(dup,NoYr) #delete any dams that don't have a year completed.\n",
    "                MM = np.delete(MM,NoYr)\n",
    "                HH = np.delete(HH,NoYr)\n",
    "                SS = np.delete(SS,NoYr)\n",
    "            \n",
    "                maxloc = np.argmax(MM) #Take the maximum storage value\n",
    "                dup = dup[maxloc]\n",
    "            \n",
    "                if len(dup)>1: #if more than one dam has the same storage value, take the largest dam height\n",
    "                    HH = DamH[dup]\n",
    "                    maxHH = np.argmax(HH)\n",
    "                    dup = dup[maxHH]\n",
    "                \n",
    "                    if len(dup) > 1: #if the dam heights are the same, take the largest ShortID arbitrarily\n",
    "                        SS = SID[dup]\n",
    "                        maxSS = np.argmax(SS)\n",
    "                        dup = dup[maxSS]\n",
    "                dupind.append(dup)\n",
    "                else: #otherwise just take the max storage\n",
    "                    maxloc = np.argmax(MM) #Take the maximum storage value\n",
    "                    dup = dup[maxloc]\n",
    "            \n",
    "                    if len(dup)>1: #if more than one dam has the same storage value, take the largest dam height\n",
    "                        HH = DamH[dup]\n",
    "                        maxHH = np.argmax(HH)\n",
    "                        dup = dup[maxHH]\n",
    "                \n",
    "                        if len(dup) > 1: #if the dam heights are the same, take the largest ShortID arbitrarily\n",
    "                            SS = SID[dup]\n",
    "                            maxSS = np.argmax(SS)\n",
    "                            dup = dup[maxSS]\n",
    "                    dupind.append(dup)\n",
    "                    continue\n",
    "            else: #otherwise none of them have a year completed\n",
    "                maxloc = np.argmax(MM) #Take the maximum storage value\n",
    "                dup = dup[maxloc]\n",
    "            \n",
    "                if len(dup)>1: #if more than one dam has the same storage value, take the largest dam height\n",
    "                    HH = DamH[dup]\n",
    "                    maxHH = np.argmax(HH)\n",
    "                    dup = dup[maxHH]\n",
    "                \n",
    "                    if len(dup) > 1: #if the dam heights are the same, take the largest ShortID arbitrarily\n",
    "                        SS = SID[dup]\n",
    "                        maxSS = np.argmax(SS)\n",
    "                        dup = dup[maxSS]\n",
    "                dupind.append(dup)\n",
    "                \n",
    "        if dupskip == i: # If the first index was the current index.\n",
    "            skip_it = jskip-1 # Skip the next j-1 indices.\n",
    "        else:\n",
    "            skip_it = 0\n",
    "                \n",
    "\n",
    "flags = flags[dupind]\n",
    "dupltable = pd.DataFrame.from_dict(dupl_ordered_dict)\n",
    "noduplicates = dupltable.loc[dupind]\n",
    "\n",
    "noduplicates.to_csv(os.path.join(out_folder,'NID_filtered_snapped_nodupl.csv'),index = False)\n",
    "\n",
    "\n",
    "print('Size after removing duplicates:',noduplicates.shape) # New database size after snapping to NHD flowlines\n",
    "print('Number of sites in database:', noduplicates.loc[noduplicates.IsSite == 1].shape)\n",
    "print('Number of Reclamation dams in database:', noduplicates.loc[noduplicates.IsUSBR == 1].shape)\n",
    "print('Number of USACE dams in database:', noduplicates.loc[noduplicates.IsUSACE == 1].shape)\n",
    "print('Number of GRanD in database:', noduplicates.loc[noduplicates.IsGRanD == 1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
